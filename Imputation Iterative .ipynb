{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4327bce4-d1db-43a0-b355-c0a855184cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGAS-Season                               1405\n",
      "CGAS-CGAS_Score                           1539\n",
      "Physical-Season                            650\n",
      "Physical-BMI                               938\n",
      "Physical-Height                            933\n",
      "Physical-Weight                            884\n",
      "Physical-Waist_Circumference              3062\n",
      "Physical-Diastolic_BP                     1006\n",
      "Physical-HeartRate                         993\n",
      "Physical-Systolic_BP                      1006\n",
      "Fitness_Endurance-Season                  2652\n",
      "Fitness_Endurance-Max_Stage               3217\n",
      "Fitness_Endurance-Time_Mins               3220\n",
      "Fitness_Endurance-Time_Sec                3220\n",
      "FGC-Season                                 614\n",
      "FGC-FGC_CU                                1638\n",
      "FGC-FGC_CU_Zone                           1678\n",
      "FGC-FGC_GSND                              2886\n",
      "FGC-FGC_GSND_Zone                         2898\n",
      "FGC-FGC_GSD                               2886\n",
      "FGC-FGC_GSD_Zone                          2897\n",
      "FGC-FGC_PU                                1650\n",
      "FGC-FGC_PU_Zone                           1689\n",
      "FGC-FGC_SRL                               1655\n",
      "FGC-FGC_SRL_Zone                          1693\n",
      "FGC-FGC_SRR                               1653\n",
      "FGC-FGC_SRR_Zone                          1691\n",
      "FGC-FGC_TL                                1636\n",
      "FGC-FGC_TL_Zone                           1675\n",
      "BIA-Season                                1815\n",
      "BIA-BIA_Activity_Level_num                1969\n",
      "BIA-BIA_BMC                               1969\n",
      "BIA-BIA_BMI                               1969\n",
      "BIA-BIA_BMR                               1969\n",
      "BIA-BIA_DEE                               1969\n",
      "BIA-BIA_ECW                               1969\n",
      "BIA-BIA_FFM                               1969\n",
      "BIA-BIA_FFMI                              1969\n",
      "BIA-BIA_FMI                               1969\n",
      "BIA-BIA_Fat                               1969\n",
      "BIA-BIA_Frame_num                         1969\n",
      "BIA-BIA_ICW                               1969\n",
      "BIA-BIA_LDM                               1969\n",
      "BIA-BIA_LST                               1969\n",
      "BIA-BIA_SMM                               1969\n",
      "BIA-BIA_TBW                               1969\n",
      "PAQ_A-Season                              3485\n",
      "PAQ_A-PAQ_A_Total                         3485\n",
      "PAQ_C-Season                              2239\n",
      "PAQ_C-PAQ_C_Total                         2239\n",
      "PCIAT-Season                              1224\n",
      "PCIAT-PCIAT_01                            1227\n",
      "PCIAT-PCIAT_02                            1226\n",
      "PCIAT-PCIAT_03                            1229\n",
      "PCIAT-PCIAT_04                            1229\n",
      "PCIAT-PCIAT_05                            1231\n",
      "PCIAT-PCIAT_06                            1228\n",
      "PCIAT-PCIAT_07                            1231\n",
      "PCIAT-PCIAT_08                            1230\n",
      "PCIAT-PCIAT_09                            1230\n",
      "PCIAT-PCIAT_10                            1227\n",
      "PCIAT-PCIAT_11                            1226\n",
      "PCIAT-PCIAT_12                            1229\n",
      "PCIAT-PCIAT_13                            1231\n",
      "PCIAT-PCIAT_14                            1228\n",
      "PCIAT-PCIAT_15                            1230\n",
      "PCIAT-PCIAT_16                            1232\n",
      "PCIAT-PCIAT_17                            1235\n",
      "PCIAT-PCIAT_18                            1232\n",
      "PCIAT-PCIAT_19                            1230\n",
      "PCIAT-PCIAT_20                            1227\n",
      "PCIAT-PCIAT_Total                         1224\n",
      "SDS-Season                                1342\n",
      "SDS-SDS_Total_Raw                         1351\n",
      "SDS-SDS_Total_T                           1354\n",
      "PreInt_EduHx-Season                        420\n",
      "PreInt_EduHx-computerinternet_hoursday     659\n",
      "sii                                       1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbmma\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9698492462311558\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      1275\n",
      "         1.0       0.94      0.99      0.96       584\n",
      "         2.0       0.92      0.88      0.90       303\n",
      "         3.0       1.00      0.19      0.31        27\n",
      "\n",
      "    accuracy                           0.97      2189\n",
      "   macro avg       0.96      0.76      0.79      2189\n",
      "weighted avg       0.97      0.97      0.97      2189\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbmma\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing 'sii' after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # type: ignore\n",
    "import numpy as np  # type: ignore\n",
    "from sklearn.pipeline import Pipeline  # type: ignore\n",
    "from sklearn.compose import ColumnTransformer  # type: ignore\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer  # noqa\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder  # type: ignore\n",
    "from sklearn.ensemble import RandomForestClassifier  # type: ignore\n",
    "from sklearn.model_selection import train_test_split  # type: ignore\n",
    "from sklearn.metrics import accuracy_score, classification_report  # type: ignore\n",
    "from sklearn.base import BaseEstimator, TransformerMixin  # type: ignore\n",
    "\n",
    "# Paths to data folders\n",
    "train_csv_path = 'data/train.csv'\n",
    "test_csv_path = 'data/test.csv'\n",
    "\n",
    "# Load the CSV files\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Display Entire List of Missing Values\n",
    "missing_values = train_df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(missing_values.to_string())\n",
    "\n",
    "# Column definitions\n",
    "numerical_cols = [\n",
    "    'Basic_Demos-Age', 'CGAS-CGAS_Score', 'Physical-BMI', 'Physical-Height', 'Physical-Weight',\n",
    "    'Physical-Waist_Circumference', 'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "    'Fitness_Endurance-Max_Stage', 'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "    'FGC-FGC_CU', 'FGC-FGC_GSND', 'FGC-FGC_GSD', 'FGC-FGC_PU', 'FGC-FGC_SRL', 'FGC-FGC_SRR', 'FGC-FGC_TL',\n",
    "    'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI', 'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW',\n",
    "    'BIA-BIA_FFM', 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST',\n",
    "    'BIA-BIA_SMM', 'BIA-BIA_TBW', 'PAQ_A-PAQ_A_Total', 'PAQ_C-PAQ_C_Total', 'PCIAT-PCIAT_Total',\n",
    "    'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T', 'PCIAT-PCIAT_01', 'PCIAT-PCIAT_02', 'PCIAT-PCIAT_03',\n",
    "    'PCIAT-PCIAT_04', 'PCIAT-PCIAT_05', 'PCIAT-PCIAT_06', 'PCIAT-PCIAT_07', 'PCIAT-PCIAT_08', 'PCIAT-PCIAT_09',\n",
    "    'PCIAT-PCIAT_10', 'PCIAT-PCIAT_11', 'PCIAT-PCIAT_12', 'PCIAT-PCIAT_13', 'PCIAT-PCIAT_14', 'PCIAT-PCIAT_15',\n",
    "    'PCIAT-PCIAT_16', 'PCIAT-PCIAT_17', 'PCIAT-PCIAT_18', 'PCIAT-PCIAT_19', 'PCIAT-PCIAT_20'\n",
    "]\n",
    "\n",
    "ordinal_categorical_cols = [\n",
    "    'Basic_Demos-Sex', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU_Zone',\n",
    "    'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR_Zone', 'FGC-FGC_TL_Zone', 'BIA-BIA_Frame_num',\n",
    "    'PreInt_EduHx-computerinternet_hoursday'\n",
    "]\n",
    "\n",
    "nominal_categorical_cols = [\n",
    "    'Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', 'Fitness_Endurance-Season',\n",
    "    'FGC-Season', 'BIA-Season', 'PAQ_A-Season', 'PAQ_C-Season', 'PCIAT-Season', 'SDS-Season',\n",
    "    'PreInt_EduHx-Season'\n",
    "]\n",
    "\n",
    "# Validate column presence in train_df\n",
    "for col_list, col_type in [\n",
    "    (numerical_cols, \"Numerical\"),\n",
    "    (ordinal_categorical_cols, \"Ordinal\"),\n",
    "    (nominal_categorical_cols, \"Nominal\")\n",
    "]:\n",
    "    for col in col_list:\n",
    "        if col not in train_df.columns:\n",
    "            print(f\"Missing {col_type} column: {col}\")\n",
    "\n",
    "# Custom transformer to select columns\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.columns]\n",
    "\n",
    "# Iterative Imputer for All Data Types\n",
    "class IterativeImputerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, random_state=42, max_iter=10, initial_strategy='mean'):\n",
    "        self.random_state = random_state\n",
    "        self.max_iter = max_iter\n",
    "        self.initial_strategy = initial_strategy\n",
    "        self.iterative_imputer = None\n",
    "        self.dummies_columns = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Encode data and store the columns\n",
    "        X_encoded = pd.get_dummies(X)\n",
    "        self.dummies_columns = X_encoded.columns\n",
    "\n",
    "        # Fit the iterative imputer on the encoded data\n",
    "        self.iterative_imputer = IterativeImputer(\n",
    "            random_state=self.random_state,\n",
    "            max_iter=self.max_iter,\n",
    "            initial_strategy=self.initial_strategy\n",
    "        )\n",
    "        self.iterative_imputer.fit(X_encoded)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.iterative_imputer is None:\n",
    "            raise RuntimeError(\"IterativeImputerTransformer must be fitted before calling transform.\")\n",
    "        \n",
    "        # Encode data and align to stored columns\n",
    "        X_encoded = pd.get_dummies(X)\n",
    "        X_encoded = X_encoded.reindex(columns=self.dummies_columns, fill_value=0)\n",
    "        \n",
    "        # Impute missing values\n",
    "        X_imputed = self.iterative_imputer.transform(X_encoded)\n",
    "        \n",
    "        # Return a DataFrame with the original index\n",
    "        return pd.DataFrame(X_imputed, columns=self.dummies_columns, index=X.index)\n",
    "\n",
    "# Numerical Pipeline\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('selector', ColumnSelector(columns=numerical_cols)),\n",
    "    ('imputer', IterativeImputerTransformer(random_state=42, max_iter=10, initial_strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Ordinal Categorical Pipeline\n",
    "ordinal_categorical_pipeline = Pipeline(steps=[\n",
    "    ('selector', ColumnSelector(columns=ordinal_categorical_cols)),\n",
    "    ('imputer', IterativeImputerTransformer(random_state=42, max_iter=10, initial_strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "# Nominal Categorical Pipeline\n",
    "nominal_categorical_pipeline = Pipeline(steps=[\n",
    "    ('selector', ColumnSelector(columns=nominal_categorical_cols)),\n",
    "    ('imputer', IterativeImputerTransformer(random_state=42, max_iter=10, initial_strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine Numerical and Categorical Pipelines\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_pipeline, numerical_cols),\n",
    "    ('ord_cat', ordinal_categorical_pipeline, ordinal_categorical_cols),\n",
    "    ('nom_cat', nominal_categorical_pipeline, nominal_categorical_cols)\n",
    "])\n",
    "\n",
    "# Continue with splitting, preprocessing, and modeling\n",
    "\n",
    "\n",
    "# Split the data into known and missing 'sii'\n",
    "train_known = train_df[train_df['sii'].notnull()].copy()\n",
    "train_missing = train_df[train_df['sii'].isnull()].copy()\n",
    "\n",
    "# Features and Target for Known 'sii'\n",
    "X_known = train_known.drop(columns=['id', 'sii'])\n",
    "y_known = train_known['sii']\n",
    "\n",
    "# Features for Missing 'sii'\n",
    "X_missing = train_missing.drop(columns=['id', 'sii'])\n",
    "\n",
    "# Split known data into training and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_known, y_known, test_size=0.8, random_state=22, stratify=y_known\n",
    ")\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "feature_preprocessing_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Fit and transform the training split\n",
    "X_train_processed = feature_preprocessing_pipeline.fit_transform(X_train_split)\n",
    "\n",
    "# Transform the validation split\n",
    "X_val_processed = feature_preprocessing_pipeline.transform(X_val_split)\n",
    "\n",
    "# Train the Random Forest classifier on the training split\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=22, class_weight='balanced')\n",
    "rf.fit(X_train_processed, y_train_split)\n",
    "\n",
    "# Predict on the validation split\n",
    "y_val_pred = rf.predict(X_val_processed)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val_split, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_split, y_val_pred))\n",
    "\n",
    "# Fit the preprocessing pipeline on the entire known data\n",
    "X_known_full = X_known\n",
    "y_known_full = y_known\n",
    "\n",
    "X_known_full_processed = feature_preprocessing_pipeline.fit_transform(X_known_full)\n",
    "\n",
    "# Retrain the Random Forest classifier on the entire known data\n",
    "rf_full = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_full.fit(X_known_full_processed, y_known_full)\n",
    "\n",
    "# Transform the missing features using the fitted pipeline\n",
    "X_missing_processed = feature_preprocessing_pipeline.transform(X_missing)\n",
    "\n",
    "# Predict 'sii' for missing data\n",
    "sii_pred = rf_full.predict(X_missing_processed)\n",
    "\n",
    "# Assign predictions to missing 'sii'\n",
    "train_missing['sii'] = sii_pred\n",
    "\n",
    "# Combine the known and imputed data\n",
    "train_df_imputed = pd.concat([train_known, train_missing], ignore_index=True)\n",
    "\n",
    "# Save the fully imputed data to CSV\n",
    "train_df_imputed.to_csv('data/train_imputed_iterative.csv', index=False)\n",
    "\n",
    "# Verify that there are no missing 'sii' values\n",
    "print(\"Missing 'sii' after imputation:\", train_df_imputed['sii'].isnull().sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
