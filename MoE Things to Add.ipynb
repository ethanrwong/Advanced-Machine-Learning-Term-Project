{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa6f1f-ab8d-4e57-838c-ee9da4282669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the MoE Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a52b06d-8310-4c83-9191-144b282bf2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoE(nn.Module):\n",
    "    def __init__(self, input_size, num_experts, expert_hidden_size, output_size, gating_hidden_size=None):\n",
    "        super(MoE, self).__init__()\n",
    "        \n",
    "        # Expert networks\n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_size, expert_hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(expert_hidden_size, output_size)\n",
    "            )\n",
    "            for _ in range(num_experts)\n",
    "        ])\n",
    "        \n",
    "        # Gating network\n",
    "        gating_hidden_size = gating_hidden_size or input_size\n",
    "        self.gating_network = nn.Sequential(\n",
    "            nn.Linear(input_size, gating_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gating_hidden_size, num_experts),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Compute gating weights\n",
    "        gating_weights = self.gating_network(x)  # [batch_size, num_experts]\n",
    "        \n",
    "        # Compute expert outputs\n",
    "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=-1)  # [batch_size, output_size, num_experts]\n",
    "        \n",
    "        # Weighted sum of expert outputs\n",
    "        output = torch.sum(expert_outputs * gating_weights.unsqueeze(1), dim=-1)  # [batch_size, output_size]\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb30a0a-f47b-4dbd-a9ec-2448e59ba5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the MyModule Class with the MoE, still need to tune the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e8827-bcd1-40c6-876b-0f014c551540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_with_moe(trial):\n",
    "    # Hyperparameters for MoE\n",
    "    num_experts = trial.suggest_int('num_experts', 2, 8)\n",
    "    expert_hidden_size = trial.suggest_categorical('expert_hidden_size', [64, 128, 256])\n",
    "    gating_hidden_size = trial.suggest_int('gating_hidden_size', 32, 128)\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "    \n",
    "    # NeuralNetClassifier with MoE\n",
    "    net = NeuralNetClassifier(\n",
    "        module=MoE,\n",
    "        module__input_size=None,  # Set dynamically after preprocessing\n",
    "        module__num_experts=num_experts,\n",
    "        module__expert_hidden_size=expert_hidden_size,\n",
    "        module__output_size=len(classes),\n",
    "        module__gating_hidden_size=gating_hidden_size,\n",
    "        max_epochs=trial.suggest_int('max_epochs', 20, 50),\n",
    "        lr=trial.suggest_float('lr', 1e-4, 1e-2, log=True),\n",
    "        optimizer=torch.optim.Adam,\n",
    "        criterion=nn.CrossEntropyLoss(weight=class_weights_tensor),\n",
    "        batch_size=256,\n",
    "        iterator_train__shuffle=True,\n",
    "        device=device,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('to_float32', to_float32),\n",
    "        ('nn', net)\n",
    "    ])\n",
    "\n",
    "    temp_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('to_float32', to_float32)\n",
    "    ])\n",
    "    temp_pipeline.fit(X_train)\n",
    "    X_train_processed_temp = temp_pipeline.transform(X_train)\n",
    "    num_input_features = X_train_processed_temp.shape[1]\n",
    "\n",
    "    # Update MoE input size dynamically\n",
    "    pipeline.named_steps['nn'].set_params(module__input_size=num_input_features)\n",
    "\n",
    "    return pipeline\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
