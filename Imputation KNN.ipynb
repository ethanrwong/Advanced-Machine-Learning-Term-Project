{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4327bce4-d1db-43a0-b355-c0a855184cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGAS-Season                               1405\n",
      "CGAS-CGAS_Score                           1539\n",
      "Physical-Season                            650\n",
      "Physical-BMI                               938\n",
      "Physical-Height                            933\n",
      "Physical-Weight                            884\n",
      "Physical-Waist_Circumference              3062\n",
      "Physical-Diastolic_BP                     1006\n",
      "Physical-HeartRate                         993\n",
      "Physical-Systolic_BP                      1006\n",
      "Fitness_Endurance-Season                  2652\n",
      "Fitness_Endurance-Max_Stage               3217\n",
      "Fitness_Endurance-Time_Mins               3220\n",
      "Fitness_Endurance-Time_Sec                3220\n",
      "FGC-Season                                 614\n",
      "FGC-FGC_CU                                1638\n",
      "FGC-FGC_CU_Zone                           1678\n",
      "FGC-FGC_GSND                              2886\n",
      "FGC-FGC_GSND_Zone                         2898\n",
      "FGC-FGC_GSD                               2886\n",
      "FGC-FGC_GSD_Zone                          2897\n",
      "FGC-FGC_PU                                1650\n",
      "FGC-FGC_PU_Zone                           1689\n",
      "FGC-FGC_SRL                               1655\n",
      "FGC-FGC_SRL_Zone                          1693\n",
      "FGC-FGC_SRR                               1653\n",
      "FGC-FGC_SRR_Zone                          1691\n",
      "FGC-FGC_TL                                1636\n",
      "FGC-FGC_TL_Zone                           1675\n",
      "BIA-Season                                1815\n",
      "BIA-BIA_Activity_Level_num                1969\n",
      "BIA-BIA_BMC                               1969\n",
      "BIA-BIA_BMI                               1969\n",
      "BIA-BIA_BMR                               1969\n",
      "BIA-BIA_DEE                               1969\n",
      "BIA-BIA_ECW                               1969\n",
      "BIA-BIA_FFM                               1969\n",
      "BIA-BIA_FFMI                              1969\n",
      "BIA-BIA_FMI                               1969\n",
      "BIA-BIA_Fat                               1969\n",
      "BIA-BIA_Frame_num                         1969\n",
      "BIA-BIA_ICW                               1969\n",
      "BIA-BIA_LDM                               1969\n",
      "BIA-BIA_LST                               1969\n",
      "BIA-BIA_SMM                               1969\n",
      "BIA-BIA_TBW                               1969\n",
      "PAQ_A-Season                              3485\n",
      "PAQ_A-PAQ_A_Total                         3485\n",
      "PAQ_C-Season                              2239\n",
      "PAQ_C-PAQ_C_Total                         2239\n",
      "PCIAT-Season                              1224\n",
      "PCIAT-PCIAT_01                            1227\n",
      "PCIAT-PCIAT_02                            1226\n",
      "PCIAT-PCIAT_03                            1229\n",
      "PCIAT-PCIAT_04                            1229\n",
      "PCIAT-PCIAT_05                            1231\n",
      "PCIAT-PCIAT_06                            1228\n",
      "PCIAT-PCIAT_07                            1231\n",
      "PCIAT-PCIAT_08                            1230\n",
      "PCIAT-PCIAT_09                            1230\n",
      "PCIAT-PCIAT_10                            1227\n",
      "PCIAT-PCIAT_11                            1226\n",
      "PCIAT-PCIAT_12                            1229\n",
      "PCIAT-PCIAT_13                            1231\n",
      "PCIAT-PCIAT_14                            1228\n",
      "PCIAT-PCIAT_15                            1230\n",
      "PCIAT-PCIAT_16                            1232\n",
      "PCIAT-PCIAT_17                            1235\n",
      "PCIAT-PCIAT_18                            1232\n",
      "PCIAT-PCIAT_19                            1230\n",
      "PCIAT-PCIAT_20                            1227\n",
      "PCIAT-PCIAT_Total                         1224\n",
      "SDS-Season                                1342\n",
      "SDS-SDS_Total_Raw                         1351\n",
      "SDS-SDS_Total_T                           1354\n",
      "PreInt_EduHx-Season                        420\n",
      "PreInt_EduHx-computerinternet_hoursday     659\n",
      "sii                                       1224\n",
      "Validation Accuracy: 0.9858382823206944\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1275\n",
      "         1.0       0.98      0.99      0.99       584\n",
      "         2.0       0.94      0.96      0.95       303\n",
      "         3.0       1.00      0.41      0.58        27\n",
      "\n",
      "    accuracy                           0.99      2189\n",
      "   macro avg       0.98      0.84      0.88      2189\n",
      "weighted avg       0.99      0.99      0.98      2189\n",
      "\n",
      "Missing 'sii' after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # type: ignore\n",
    "import numpy as np  # type: ignore\n",
    "from sklearn.pipeline import Pipeline  # type: ignore\n",
    "from sklearn.compose import ColumnTransformer  # type: ignore\n",
    "from sklearn.impute import KNNImputer  # Import for KNN imputation\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder  # type: ignore\n",
    "from sklearn.ensemble import RandomForestClassifier  # type: ignore\n",
    "from sklearn.model_selection import train_test_split  # type: ignore\n",
    "from sklearn.metrics import accuracy_score, classification_report  # type: ignore\n",
    "from sklearn.base import BaseEstimator, TransformerMixin  # type: ignore\n",
    "import joblib  # type: ignore\n",
    "import os\n",
    "import pyarrow.parquet as pq  # type: ignore\n",
    "from glob import glob\n",
    "\n",
    "# Paths to data folders\n",
    "train_csv_path = 'data/train.csv'\n",
    "test_csv_path = 'data/test.csv'\n",
    "series_train_path = 'data/series_train.parquet'\n",
    "series_test_path = 'data/series_test.parquet'\n",
    "\n",
    "# Load the CSV files\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Display Entire List of Missing Values\n",
    "missing_values = train_df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(missing_values.to_string())\n",
    "\n",
    "features = train_df.drop(columns=['id', 'sii'])\n",
    "target = train_df['sii']\n",
    "\n",
    "# Numerical Columns\n",
    "numerical_cols = [\n",
    "    'Basic_Demos-Age',\n",
    "    'CGAS-CGAS_Score',\n",
    "    'Physical-BMI',\n",
    "    'Physical-Height',\n",
    "    'Physical-Weight',\n",
    "    'Physical-Waist_Circumference',\n",
    "    'Physical-Diastolic_BP',\n",
    "    'Physical-HeartRate',\n",
    "    'Physical-Systolic_BP',\n",
    "    'Fitness_Endurance-Max_Stage',\n",
    "    'Fitness_Endurance-Time_Mins',\n",
    "    'Fitness_Endurance-Time_Sec',\n",
    "    'FGC-FGC_CU',\n",
    "    'FGC-FGC_GSND',\n",
    "    'FGC-FGC_GSD',\n",
    "    'FGC-FGC_PU',\n",
    "    'FGC-FGC_SRL',\n",
    "    'FGC-FGC_SRR',\n",
    "    'FGC-FGC_TL',\n",
    "    'BIA-BIA_Activity_Level_num',\n",
    "    'BIA-BIA_BMC',\n",
    "    'BIA-BIA_BMI',\n",
    "    'BIA-BIA_BMR',\n",
    "    'BIA-BIA_DEE',\n",
    "    'BIA-BIA_ECW',\n",
    "    'BIA-BIA_FFM',\n",
    "    'BIA-BIA_FFMI',\n",
    "    'BIA-BIA_FMI',\n",
    "    'BIA-BIA_Fat',\n",
    "    'BIA-BIA_ICW',\n",
    "    'BIA-BIA_LDM',\n",
    "    'BIA-BIA_LST',\n",
    "    'BIA-BIA_SMM',\n",
    "    'BIA-BIA_TBW',\n",
    "    'PAQ_A-PAQ_A_Total',\n",
    "    'PAQ_C-PAQ_C_Total',\n",
    "    'PCIAT-PCIAT_Total',\n",
    "    'SDS-SDS_Total_Raw',\n",
    "    'SDS-SDS_Total_T',\n",
    "    'PCIAT-PCIAT_01',\n",
    "    'PCIAT-PCIAT_02',\n",
    "    'PCIAT-PCIAT_03',\n",
    "    'PCIAT-PCIAT_04',\n",
    "    'PCIAT-PCIAT_05',\n",
    "    'PCIAT-PCIAT_06',\n",
    "    'PCIAT-PCIAT_07',\n",
    "    'PCIAT-PCIAT_08',\n",
    "    'PCIAT-PCIAT_09',\n",
    "    'PCIAT-PCIAT_10',\n",
    "    'PCIAT-PCIAT_11',\n",
    "    'PCIAT-PCIAT_12',\n",
    "    'PCIAT-PCIAT_13',\n",
    "    'PCIAT-PCIAT_14',\n",
    "    'PCIAT-PCIAT_15',\n",
    "    'PCIAT-PCIAT_16',\n",
    "    'PCIAT-PCIAT_17',\n",
    "    'PCIAT-PCIAT_18',\n",
    "    'PCIAT-PCIAT_19',\n",
    "    'PCIAT-PCIAT_20'\n",
    "]\n",
    "\n",
    "# Ordinal Categorical Columns\n",
    "ordinal_categorical_cols = [\n",
    "    'Basic_Demos-Sex',\n",
    "    'FGC-FGC_CU_Zone',\n",
    "    'FGC-FGC_GSND_Zone',\n",
    "    'FGC-FGC_GSD_Zone',\n",
    "    'FGC-FGC_PU_Zone',\n",
    "    'FGC-FGC_SRL_Zone',\n",
    "    'FGC-FGC_SRR_Zone',\n",
    "    'FGC-FGC_TL_Zone',\n",
    "    'BIA-BIA_Activity_Level_num',\n",
    "    'BIA-BIA_Frame_num',\n",
    "    'PreInt_EduHx-computerinternet_hoursday'\n",
    "]\n",
    "\n",
    "# Nominal Categorical Columns\n",
    "nominal_categorical_cols = [\n",
    "    'Basic_Demos-Enroll_Season',\n",
    "    'CGAS-Season',\n",
    "    'Physical-Season',\n",
    "    'Fitness_Endurance-Season',\n",
    "    'FGC-Season',\n",
    "    'BIA-Season',\n",
    "    'PAQ_A-Season',\n",
    "    'PAQ_C-Season',\n",
    "    'PCIAT-Season',\n",
    "    'SDS-Season',\n",
    "    'PreInt_EduHx-Season'\n",
    "]\n",
    "\n",
    "# Validate column presence in train_df\n",
    "for col_list, col_type in [\n",
    "    (numerical_cols, \"Numerical\"),\n",
    "    (ordinal_categorical_cols, \"Ordinal\"),\n",
    "    (nominal_categorical_cols, \"Nominal\")\n",
    "]:\n",
    "    for col in col_list:\n",
    "        if col not in train_df.columns:\n",
    "            print(f\"Missing {col_type} column: {col}\")\n",
    "\n",
    "# Custom transformer to select columns\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.columns]\n",
    "\n",
    "# Numerical Pipeline with KNN Imputation\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('selector', ColumnSelector(columns=numerical_cols)),\n",
    "    ('imputer', KNNImputer(n_neighbors=5, weights='distance')),  # KNN imputation for numerical data\n",
    "    ('scaler', StandardScaler())  # Scale features\n",
    "])\n",
    "\n",
    "# Ordinal Categorical Pipeline with KNN Imputation\n",
    "ordinal_categorical_pipeline = Pipeline(steps=[\n",
    "    ('selector', ColumnSelector(columns=ordinal_categorical_cols)),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),  # Encode as numerical\n",
    "    ('imputer', KNNImputer(n_neighbors=5, weights='distance'))  # KNN imputation for ordinal columns\n",
    "])\n",
    "\n",
    "# Nominal Categorical Pipeline with KNN Imputation\n",
    "nominal_categorical_pipeline = Pipeline(steps=[\n",
    "    ('selector', ColumnSelector(columns=nominal_categorical_cols)),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),  # Encode as numerical\n",
    "    ('imputer', KNNImputer(n_neighbors=5, weights='distance'))  # KNN imputation for nominal columns\n",
    "])\n",
    "\n",
    "# Combine Numerical and Categorical Pipelines\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_pipeline, numerical_cols),\n",
    "    ('ord_cat', ordinal_categorical_pipeline, ordinal_categorical_cols),\n",
    "    ('nom_cat', nominal_categorical_pipeline, nominal_categorical_cols)\n",
    "])\n",
    "\n",
    "# Split the data into known and missing 'sii'\n",
    "train_known = train_df[train_df['sii'].notnull()].copy()\n",
    "train_missing = train_df[train_df['sii'].isnull()].copy()\n",
    "\n",
    "# Features and Target for Known 'sii'\n",
    "X_known = train_known.drop(columns=['id', 'sii'])\n",
    "y_known = train_known['sii']\n",
    "\n",
    "# Features for Missing 'sii'\n",
    "X_missing = train_missing.drop(columns=['id', 'sii'])\n",
    "\n",
    "# Split known data into training and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_known, y_known, test_size=0.8, random_state=22, stratify=y_known\n",
    ")\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "feature_preprocessing_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Fit and transform the training split\n",
    "X_train_processed = feature_preprocessing_pipeline.fit_transform(X_train_split)\n",
    "\n",
    "# Transform the validation split\n",
    "X_val_processed = feature_preprocessing_pipeline.transform(X_val_split)\n",
    "\n",
    "# Train the Random Forest classifier on the training split\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=22, class_weight='balanced')\n",
    "rf.fit(X_train_processed, y_train_split)\n",
    "\n",
    "# Predict on the validation split\n",
    "y_val_pred = rf.predict(X_val_processed)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val_split, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_split, y_val_pred))\n",
    "\n",
    "# Fit the preprocessing pipeline on the entire known data\n",
    "X_known_full = X_known\n",
    "y_known_full = y_known\n",
    "\n",
    "X_known_full_processed = feature_preprocessing_pipeline.fit_transform(X_known_full)\n",
    "\n",
    "# Retrain the Random Forest classifier on the entire known data\n",
    "rf_full = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_full.fit(X_known_full_processed, y_known_full)\n",
    "\n",
    "# Transform the missing features using the fitted pipeline\n",
    "X_missing_processed = feature_preprocessing_pipeline.transform(X_missing)\n",
    "\n",
    "# Predict 'sii' for missing data\n",
    "sii_pred = rf_full.predict(X_missing_processed)\n",
    "\n",
    "# Assign predictions to missing 'sii'\n",
    "train_missing['sii'] = sii_pred\n",
    "\n",
    "# Combine the known and imputed data\n",
    "train_df_imputed = pd.concat([train_known, train_missing], ignore_index=True)\n",
    "\n",
    "# Save the fully imputed data to CSV\n",
    "train_df_imputed.to_csv('data/train_imputed_knn.csv', index=False)\n",
    "\n",
    "# Verify that there are no missing 'sii' values\n",
    "print(\"Missing 'sii' after imputation:\", train_df_imputed['sii'].isnull().sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
